python3 > -u -m torch.distributed.launch --nproc_per_node 8 --nnodes 1 --node_rank 0 --master_addr localhost --master_port 6002 .//finetune_bert_bmt.py --model-config /data/home/scv0540/.cache/model_center/bert-base-cased/ --base-path ./ --dataset_name BoolQ --batch-size 56 --lr 0.0001 --max-decoder-length 512 --train-iters 1400 --lr-decay-style constant --weight-decay 1e-2 --loss-scale 128
/data/home/scv0540/miniconda3/envs/bmpretrain/lib/python3.7/site-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  FutureWarning,
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
====================== Initialization ============================================ Initialization ============================================ Initialization ============================================ Initialization ============================================ Initialization ============================================ Initialization ======================





rank :          6
local_rank :    6
world_size :    8
local_size :    8
master :        localhost:6002
device :        6
cpus :          [50, 51, 52, 53, 54, 55, 56, 57]
rank :          5
local_rank :    5
world_size :    8
local_size :    8
master :        localhost:6002
device :        5
cpus :          [42, 43, 44, 45, 46, 47, 48, 49]
rank :          3
local_rank :    3
world_size :    8
local_size :    8
master :        localhost:6002
device :        3
cpus :          [26, 27, 28, 29, 30, 31, 32, 33]
====================== Initialization ======================rank :          2
local_rank :    2
world_size :    8
local_size :    8
master :        localhost:6002
device :        2
cpus :          [18, 19, 20, 21, 22, 23, 24, 25]
rank :          4
local_rank :    4
world_size :    8
local_size :    8
master :        localhost:6002
device :        4
cpus :          [34, 35, 36, 37, 38, 39, 40, 41]
rank :          0
local_rank :    0
world_size :    8
local_size :    8
master :        localhost:6002
device :        0
cpus :          [2, 3, 4, 5, 6, 7, 8, 9]



====================== Initialization ======================



rank :          1
local_rank :    1
world_size :    8
local_size :    8
master :        localhost:6002
device :        1
cpus :          [10, 11, 12, 13, 14, 15, 16, 17]


rank :          7
local_rank :    7
world_size :    8
local_size :    8
master :        localhost:6002
device :        7
cpus :          [58, 59, 60, 61, 62, 63, 64, 65]

load from local file: /data/home/scv0540/.cache/model_center/bert-base-cased/
load from local file: /data/home/scv0540/.cache/model_center/bert-base-cased/
load from local file: /data/home/scv0540/.cache/model_center/bert-base-cased/
Model mem
 |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   32071 KB |  206047 KB |    1044 MB |    1013 MB |
|       from large pool |   10874 KB |  184850 KB |    1019 MB |    1008 MB |
|       from small pool |   21197 KB |   21424 KB |      25 MB |       4 MB |
|---------------------------------------------------------------------------|
| Active memory         |   32071 KB |  206047 KB |    1044 MB |    1013 MB |
|       from large pool |   10874 KB |  184850 KB |    1019 MB |    1008 MB |
|       from small pool |   21197 KB |   21424 KB |      25 MB |       4 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  221184 KB |  221184 KB |  221184 KB |       0 B  |
|       from large pool |  196608 KB |  196608 KB |  196608 KB |       0 B  |
|       from small pool |   24576 KB |   24576 KB |   24576 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   10936 KB |   80179 KB |    2346 MB |    2335 MB |
|       from large pool |    9606 KB |   78848 KB |    2320 MB |    2310 MB |
|       from small pool |    1330 KB |    3378 KB |      26 MB |      25 MB |
|---------------------------------------------------------------------------|
| Allocations           |     206    |     209    |    2133    |    1927    |
|       from large pool |       2    |       4    |     156    |     154    |
|       from small pool |     204    |     207    |    1977    |    1773    |
|---------------------------------------------------------------------------|
| Active allocs         |     206    |     209    |    2133    |    1927    |
|       from large pool |       2    |       4    |     156    |     154    |
|       from small pool |     204    |     207    |    1977    |    1773    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      15    |      15    |      15    |       0    |
|       from large pool |       3    |       3    |       3    |       0    |
|       from small pool |      12    |      12    |      12    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      10    |      13    |     849    |     839    |
|       from large pool |       1    |       3    |      53    |      52    |
|       from small pool |       9    |      11    |     796    |     787    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

 name                                                                   shape               max       min       std       mean      grad_std  grad_mean
 bert.input_embedding.weight                                            (28996, 768)        0.6499    -0.9722   0.0448    -0.0138   None      None     
 bert.position_embedding.weight                                         (512, 768)          0.1921    -0.9434   0.0145    0.0000    None      None     
 bert.token_type_embedding.weight                                       (2, 768)            0.0466    -0.6826   0.0258    -0.0005   None      None     
 bert.encoder.layers.0.self_att.layernorm_before_attention.weight       (768,)              0.9746    0.1676    0.0925    0.8867    None      None     
 bert.encoder.layers.0.self_att.layernorm_before_attention.bias         (768,)              0.9834    -0.1656   0.0600    -0.0199   None      None     
 bert.encoder.layers.0.self_att.self_attention.project_q.weight         (768, 768)          0.2683    -0.2900   0.0345    -0.0000   None      None     
 bert.encoder.layers.0.self_att.self_attention.project_q.bias           (768,)              0.6743    -0.7212   0.2145    -0.0103   None      None     
 bert.encoder.layers.0.self_att.self_attention.project_k.weight         (768, 768)          0.4199    -0.5693   0.0340    0.0000    None      None     
 bert.encoder.layers.0.self_att.self_attention.project_k.bias           (768,)              0.0073    -0.0072   0.0016    -0.0000   None      None     
 bert.encoder.layers.0.self_att.self_attention.project_v.weight         (768, 768)          0.1281    -0.1353   0.0253    0.0000    None      None     
 bert.encoder.layers.0.self_att.self_attention.project_v.bias           (768,)              0.2063    -0.2252   0.0372    0.0008    None      None     
 bert.encoder.layers.0.self_att.self_attention.attention_out.weight     (768, 768)          0.4851    -0.5225   0.0248    -0.0000   None      None     
 bert.encoder.layers.0.self_att.self_attention.attention_out.bias       (768,)              0.1058    -0.5239   0.0330    -0.0018   None      None     
 bert.encoder.layers.0.ffn.layernorm_before_ffn.weight                  (768,)              2.6230    0.5635    0.0899    0.9873    None      None     
 bert.encoder.layers.0.ffn.layernorm_before_ffn.bias                    (768,)              0.8711    -3.6367   0.2489    -0.0130   None      None     
 bert.encoder.layers.0.ffn.ffn.w_in.w.weight                            (3072, 768)         0.3503    -0.2988   0.0333    -0.0000   None      None     
 bert.encoder.layers.0.ffn.ffn.w_in.w.bias                              (3072,)             0.3164    -0.3494   0.0414    -0.0818   None      None     
 bert.encoder.layers.0.ffn.ffn.w_out.weight                             (768, 3072)         1.0068    -1.5127   0.0313    -0.0000   None      None     
 bert.encoder.layers.0.ffn.ffn.w_out.bias                               (768,)              0.2944    -0.3145   0.0690    -0.0007   None      None     
 bert.encoder.layers.1.self_att.layernorm_before_attention.weight       (768,)              0.9458    0.1945    0.0537    0.8940    None      None     
 bert.encoder.layers.1.self_att.layernorm_before_attention.bias         (768,)              0.2666    -1.5439   0.0737    -0.0392   None      None     
 bert.encoder.layers.1.self_att.self_attention.project_q.weight         (768, 768)          0.2976    -0.2976   0.0384    0.0000    None      None     
 bert.encoder.layers.1.self_att.self_attention.project_q.bias           (768,)              0.4204    -0.5024   0.1204    -0.0031   None      None     
 bert.encoder.layers.1.self_att.self_attention.project_k.weight         (768, 768)          0.3010    -0.3325   0.0383    -0.0000   None      None     
 bert.encoder.layers.1.self_att.self_attention.project_k.bias           (768,)              0.0106    -0.0127   0.0028    -0.0001   None      None     
 bert.encoder.layers.1.self_att.self_attention.project_v.weight         (768, 768)          0.1305    -0.1503   0.0266    -0.0000   None      None     
 bert.encoder.layers.1.self_att.self_attention.project_v.bias           (768,)              0.2260    -0.1929   0.0305    0.0012    None      None     
 bert.encoder.layers.1.self_att.self_attention.attention_out.weight     (768, 768)          0.2766    -0.3655   0.0266    0.0000    None      None     
 bert.encoder.layers.1.self_att.self_attention.attention_out.bias       (768,)              0.1963    -0.3164   0.0673    -0.0011   None      None     
 bert.encoder.layers.1.ffn.layernorm_before_ffn.weight                  (768,)              2.6094    0.7412    0.0734    0.9614    None      None     
 bert.encoder.layers.1.ffn.layernorm_before_ffn.bias                    (768,)              0.3706    -2.1426   0.1388    -0.0088   None      None     
 bert.encoder.layers.1.ffn.ffn.w_in.w.weight                            (3072, 768)         0.3342    -0.3401   0.0359    -0.0000   None      None     
 bert.encoder.layers.1.ffn.ffn.w_in.w.bias                              (3072,)             0.4585    -0.2292   0.0390    -0.0676   None      None     
 bert.encoder.layers.1.ffn.ffn.w_out.weight                             (768, 3072)         2.2207    -2.2461   0.0342    -0.0000   None      None     
 bert.encoder.layers.1.ffn.ffn.w_out.bias                               (768,)              0.1625    -0.4158   0.0533    -0.0009   None      None     
 bert.encoder.layers.2.self_att.layernorm_before_attention.weight       (768,)              0.9985    0.1205    0.0522    0.9424    None      None     
 bert.encoder.layers.2.self_att.layernorm_before_attention.bias         (768,)              0.4819    -0.9204   0.0700    -0.0346   None      None     
 bert.encoder.layers.2.self_att.self_attention.project_q.weight         (768, 768)          0.4839    -0.4656   0.0412    -0.0000   None      None     
 bert.encoder.layers.2.self_att.self_attention.project_q.bias           (768,)              0.5278    -0.4121   0.0910    0.0009    None      None     
 bert.encoder.layers.2.self_att.self_attention.project_k.weight         (768, 768)          0.5073    -0.5688   0.0406    -0.0001   None      None     
 bert.encoder.layers.2.self_att.self_attention.project_k.bias           (768,)              0.0094    -0.0091   0.0024    0.0001    None      None     
 bert.encoder.layers.2.self_att.self_attention.project_v.weight         (768, 768)          0.1439    -0.1453   0.0276    -0.0000   None      None     
 bert.encoder.layers.2.self_att.self_attention.project_v.bias           (768,)              0.2810    -0.2446   0.0330    0.0005    None      None     
 bert.encoder.layers.2.self_att.self_attention.attention_out.weight     (768, 768)          0.1903    -0.1954   0.0267    -0.0000   None      None     
 bert.encoder.layers.2.self_att.self_attention.attention_out.bias       (768,)              0.2549    -0.3289   0.0693    -0.0007   None      None     
 bert.encoder.layers.2.ffn.layernorm_before_ffn.weight                  (768,)              2.0195    0.7017    0.0596    0.9399    None      None     
 bert.encoder.layers.2.ffn.layernorm_before_ffn.bias                    (768,)              0.4290    -1.6445   0.1173    -0.0054   None      None     
 bert.encoder.layers.2.ffn.ffn.w_in.w.weight                            (3072, 768)         0.3923    -0.3000   0.0368    -0.0002   None      None     
 bert.encoder.layers.2.ffn.ffn.w_in.w.bias                              (3072,)             0.4434    -0.2500   0.0418    -0.0654   None      None     
 bert.encoder.layers.2.ffn.ffn.w_out.weight                             (768, 3072)         2.7383    -1.6328   0.0351    -0.0000   None      None     
 bert.encoder.layers.2.ffn.ffn.w_out.bias                               (768,)              0.1473    -0.4915   0.0502    -0.0006   None      None     
 bert.encoder.layers.3.self_att.layernorm_before_attention.weight       (768,)              0.9941    0.2180    0.0479    0.9326    None      None     
 bert.encoder.layers.3.self_att.layernorm_before_attention.bias         (768,)              0.2430    -0.7437   0.0594    -0.0211   None      None     
 bert.encoder.layers.3.self_att.self_attention.project_q.weight         (768, 768)          0.4761    -0.4333   0.0403    -0.0000   None      None     
 bert.encoder.layers.3.self_att.self_attention.project_q.bias           (768,)              0.3376    -0.3357   0.0757    0.0026    None      None     
 bert.encoder.layers.3.self_att.self_attention.project_k.weight         (768, 768)          0.4924    -0.5063   0.0400    0.0000    None      None     
 bert.encoder.layers.3.self_att.self_attention.project_k.bias           (768,)              0.0097    -0.0090   0.0026    0.0000    None      None     
 bert.encoder.layers.3.self_att.self_attention.project_v.weight         (768, 768)          0.1995    -0.1641   0.0291    -0.0000   None      None     
 bert.encoder.layers.3.self_att.self_attention.project_v.bias           (768,)              0.1416    -0.1611   0.0226    -0.0015   None      None     
 bert.encoder.layers.3.self_att.self_attention.attention_out.weight     (768, 768)          0.2644    -0.1709   0.0271    -0.0000   None      None     
 bert.encoder.layers.3.self_att.self_attention.attention_out.bias       (768,)              0.1597    -0.2052   0.0457    -0.0008   None      None     
 bert.encoder.layers.3.ffn.layernorm_before_ffn.weight                  (768,)              2.1934    0.7642    0.0692    0.9336    None      None     
 bert.encoder.layers.3.ffn.layernorm_before_ffn.bias                    (768,)              0.5083    -1.2900   0.1083    -0.0065   None      None     
 bert.encoder.layers.3.ffn.ffn.w_in.w.weight                            (3072, 768)         0.4424    -0.4158   0.0372    -0.0002   None      None     
 bert.encoder.layers.3.ffn.ffn.w_in.w.bias                              (3072,)             0.3794    -0.3298   0.0447    -0.0619   None      None     
 bert.encoder.layers.3.ffn.ffn.w_out.weight                             (768, 3072)         3.7988    -1.6719   0.0355    -0.0000   None      None     
 bert.encoder.layers.3.ffn.ffn.w_out.bias                               (768,)              0.2087    -0.5015   0.0556    -0.0006   None      None     
 bert.encoder.layers.4.self_att.layernorm_before_attention.weight       (768,)              0.9883    0.2769    0.0408    0.9258    None      None     
 bert.encoder.layers.4.self_att.layernorm_before_attention.bias         (768,)              0.2524    -0.4597   0.0488    -0.0130   None      None     
 bert.encoder.layers.4.self_att.self_attention.project_q.weight         (768, 768)          0.2522    -0.2537   0.0399    0.0000    None      None     
 bert.encoder.layers.4.self_att.self_attention.project_q.bias           (768,)              0.4563    -0.4492   0.0905    0.0037    None      None     
 bert.encoder.layers.4.self_att.self_attention.project_k.weight         (768, 768)          0.2964    -0.3132   0.0398    -0.0000   None      None     
 bert.encoder.layers.4.self_att.self_attention.project_k.bias           (768,)              0.0177    -0.0159   0.0036    -0.0003   None      None     
 bert.encoder.layers.4.self_att.self_attention.project_v.weight         (768, 768)          0.3772    -0.1674   0.0326    -0.0000   None      None     
 bert.encoder.layers.4.self_att.self_attention.project_v.bias           (768,)              0.1201    -0.0847   0.0200    0.0003    None      None     
 bert.encoder.layers.4.self_att.self_attention.attention_out.weight     (768, 768)          0.3958    -0.3706   0.0298    0.0000    None      None     
 bert.encoder.layers.4.self_att.self_attention.attention_out.bias       (768,)              0.2369    -0.2854   0.0701    -0.0003   None      None     
 bert.encoder.layers.4.ffn.layernorm_before_ffn.weight                  (768,)              2.5703    0.7271    0.0828    0.9233    None      None     
 bert.encoder.layers.4.ffn.layernorm_before_ffn.bias                    (768,)              0.6099    -1.2451   0.1055    -0.0078   None      None     
 bert.encoder.layers.4.ffn.ffn.w_in.w.weight                            (3072, 768)         0.3687    -0.4192   0.0373    -0.0002   None      None     
 bert.encoder.layers.4.ffn.ffn.w_in.w.bias                              (3072,)             0.3958    -0.3721   0.0462    -0.0600   None      None     
 bert.encoder.layers.4.ffn.ffn.w_out.weight                             (768, 3072)         4.2383    -1.3252   0.0356    -0.0000   None      None     
 bert.encoder.layers.4.ffn.ffn.w_out.bias                               (768,)              0.2605    -0.4302   0.0490    -0.0006   None      None     
 bert.encoder.layers.5.self_att.layernorm_before_attention.weight       (768,)              1.0322    0.3328    0.0449    0.9722    None      None     
 bert.encoder.layers.5.self_att.layernorm_before_attention.bias         (768,)              0.2561    -0.5342   0.0454    -0.0089   None      None     
 bert.encoder.layers.5.self_att.self_attention.project_q.weight         (768, 768)          0.2815    -0.2754   0.0432    -0.0000   None      None     
 bert.encoder.layers.5.self_att.self_attention.project_q.bias           (768,)              0.3513    -0.3462   0.0800    0.0002    None      None     
 bert.encoder.layers.5.self_att.self_attention.project_k.weight         (768, 768)          0.2776    -0.3123   0.0425    0.0000    None      None     
 bert.encoder.layers.5.self_att.self_attention.project_k.bias           (768,)              0.0120    -0.0118   0.0033    0.0002    None      None     
 bert.encoder.layers.5.self_att.self_attention.project_v.weight         (768, 768)          0.1700    -0.1670   0.0309    -0.0000   None      None     
 bert.encoder.layers.5.self_att.self_attention.project_v.bias           (768,)              0.0768    -0.0916   0.0203    -0.0004   None      None     
 bert.encoder.layers.5.self_att.self_attention.attention_out.weight     (768, 768)          0.2002    -0.1975   0.0290    0.0000    None      None     
 bert.encoder.layers.5.self_att.self_attention.attention_out.bias       (768,)              0.3589    -0.1627   0.0427    0.0002    None      None     
 bert.encoder.layers.5.ffn.layernorm_before_ffn.weight                  (768,)              2.4375    0.7544    0.0756    0.9185    None      None     
 bert.encoder.layers.5.ffn.layernorm_before_ffn.bias                    (768,)              0.7285    -1.0576   0.0999    -0.0085   None      None     
 bert.encoder.layers.5.ffn.ffn.w_in.w.weight                            (3072, 768)         0.2876    -0.4426   0.0374    -0.0002   None      None     
 bert.encoder.layers.5.ffn.ffn.w_in.w.bias                              (3072,)             0.2991    -0.3596   0.0475    -0.0616   None      None     
 bert.encoder.layers.5.ffn.ffn.w_out.weight                             (768, 3072)         4.1992    -1.4199   0.0359    -0.0000   None      None     
 bert.encoder.layers.5.ffn.ffn.w_out.bias                               (768,)              0.3142    -0.6216   0.0522    -0.0008   None      None     
 bert.encoder.layers.6.self_att.layernorm_before_attention.weight       (768,)              1.0449    0.1704    0.0460    0.9819    None      None     
 bert.encoder.layers.6.self_att.layernorm_before_attention.bias         (768,)              0.2262    -0.4934   0.0439    -0.0068   None      None     
 bert.encoder.layers.6.self_att.self_attention.project_q.weight         (768, 768)          0.2307    -0.2595   0.0435    0.0001    None      None     
 bert.encoder.layers.6.self_att.self_attention.project_q.bias           (768,)              0.4468    -0.4441   0.0909    -0.0039   None      None     
 bert.encoder.layers.6.self_att.self_attention.project_k.weight         (768, 768)          0.2886    -0.2986   0.0425    -0.0000   None      None     
 bert.encoder.layers.6.self_att.self_attention.project_k.bias           (768,)              0.0096    -0.0092   0.0032    -0.0002   None      None     
 bert.encoder.layers.6.self_att.self_attention.project_v.weight         (768, 768)          0.1600    -0.1707   0.0307    0.0000    None      None     
 bert.encoder.layers.6.self_att.self_attention.project_v.bias           (768,)              0.1364    -0.0914   0.0253    0.0007    None      None     
 bert.encoder.layers.6.self_att.self_attention.attention_out.weight     (768, 768)          0.1909    -0.3115   0.0292    -0.0000   None      None     
 bert.encoder.layers.6.self_att.self_attention.attention_out.bias       (768,)              0.4705    -0.1366   0.0473    0.0003    None      None     
 bert.encoder.layers.6.ffn.layernorm_before_ffn.weight                  (768,)              2.5996    0.7432    0.0800    0.9272    None      None     
 bert.encoder.layers.6.ffn.layernorm_before_ffn.bias                    (768,)              0.8804    -1.0117   0.1002    -0.0094   None      None     
 bert.encoder.layers.6.ffn.ffn.w_in.w.weight                            (3072, 768)         0.2532    -0.2805   0.0376    -0.0002   None      None     
 bert.encoder.layers.6.ffn.ffn.w_in.w.bias                              (3072,)             0.2566    -0.3237   0.0443    -0.0612   None      None     
 bert.encoder.layers.6.ffn.ffn.w_out.weight                             (768, 3072)         3.2227    -1.1104   0.0358    -0.0000   None      None     
 bert.encoder.layers.6.ffn.ffn.w_out.bias                               (768,)              0.5225    -0.7407   0.0738    -0.0009   None      None     
 bert.encoder.layers.7.self_att.layernorm_before_attention.weight       (768,)              1.0205    0.1566    0.0487    0.9507    None      None     
 bert.encoder.layers.7.self_att.layernorm_before_attention.bias         (768,)              0.3101    -0.4802   0.0448    -0.0117   None      None     
 bert.encoder.layers.7.self_att.self_attention.project_q.weight         (768, 768)          0.2920    -0.2371   0.0420    0.0000    None      None     
 bert.encoder.layers.7.self_att.self_attention.project_q.bias           (768,)              0.4612    -0.4651   0.1068    -0.0017   None      None     
 bert.encoder.layers.7.self_att.self_attention.project_k.weight         (768, 768)          0.3152    -0.3367   0.0415    0.0000    None      None     
 bert.encoder.layers.7.self_att.self_attention.project_k.bias           (768,)              0.0130    -0.0204   0.0037    0.0001    None      None     
 bert.encoder.layers.7.self_att.self_attention.project_v.weight         (768, 768)          0.1578    -0.1569   0.0317    0.0000    None      None     
 bert.encoder.layers.7.self_att.self_attention.project_v.bias           (768,)              0.1528    -0.1885   0.0324    -0.0001   None      None     
 bert.encoder.layers.7.self_att.self_attention.attention_out.weight     (768, 768)          0.2866    -0.2625   0.0303    0.0000    None      None     
 bert.encoder.layers.7.self_att.self_attention.attention_out.bias       (768,)              0.6006    -0.1328   0.0493    0.0005    None      None     
 bert.encoder.layers.7.ffn.layernorm_before_ffn.weight                  (768,)              2.4258    0.7939    0.0759    0.9258    None      None     
 bert.encoder.layers.7.ffn.layernorm_before_ffn.bias                    (768,)              0.7681    -1.0547   0.0984    -0.0106   None      None     
 bert.encoder.layers.7.ffn.ffn.w_in.w.weight                            (3072, 768)         0.4163    -0.3708   0.0365    -0.0001   None      None     
 bert.encoder.layers.7.ffn.ffn.w_in.w.bias                              (3072,)             0.2744    -0.3193   0.0407    -0.0638   None      None     
 bert.encoder.layers.7.ffn.ffn.w_out.weight                             (768, 3072)         0.3953    -2.7891   0.0351    -0.0000   None      None     
 bert.encoder.layers.7.ffn.ffn.w_out.bias                               (768,)              0.2502    -0.7915   0.0792    -0.0007   None      None     
 bert.encoder.layers.8.self_att.layernorm_before_attention.weight       (768,)              1.0303    0.1990    0.0402    0.9141    None      None     
 bert.encoder.layers.8.self_att.layernorm_before_attention.bias         (768,)              0.2207    -0.5234   0.0470    -0.0253   None      None     
 bert.encoder.layers.8.self_att.self_attention.project_q.weight         (768, 768)          0.2162    -0.2177   0.0414    0.0000    None      None     
 bert.encoder.layers.8.self_att.self_attention.project_q.bias           (768,)              0.4348    -0.4316   0.1057    -0.0019   None      None     
 bert.encoder.layers.8.self_att.self_attention.project_k.weight         (768, 768)          0.2747    -0.2505   0.0413    0.0000    None      None     
 bert.encoder.layers.8.self_att.self_attention.project_k.bias           (768,)              0.0212    -0.0150   0.0047    0.0001    None      None     
 bert.encoder.layers.8.self_att.self_attention.project_v.weight         (768, 768)          0.1742    -0.1863   0.0327    -0.0000   None      None     
 bert.encoder.layers.8.self_att.self_attention.project_v.bias           (768,)              0.0879    -0.1459   0.0247    -0.0000   None      None     
 bert.encoder.layers.8.self_att.self_attention.attention_out.weight     (768, 768)          0.2834    -0.2153   0.0307    0.0000    None      None     
 bert.encoder.layers.8.self_att.self_attention.attention_out.bias       (768,)              0.5073    -0.1470   0.0452    0.0003    None      None     
 bert.encoder.layers.8.ffn.layernorm_before_ffn.weight                  (768,)              2.6758    0.8086    0.0823    0.9194    None      None     
 bert.encoder.layers.8.ffn.layernorm_before_ffn.bias                    (768,)              0.4741    -0.9985   0.0920    -0.0117   None      None     
 bert.encoder.layers.8.ffn.ffn.w_in.w.weight                            (3072, 768)         0.6543    -0.5469   0.0360    -0.0001   None      None     
 bert.encoder.layers.8.ffn.ffn.w_in.w.bias                              (3072,)             0.3008    -0.2834   0.0338    -0.0637   None      None     
 bert.encoder.layers.8.ffn.ffn.w_out.weight                             (768, 3072)         0.5073    -4.5977   0.0347    -0.0000   None      None     
 bert.encoder.layers.8.ffn.ffn.w_out.bias                               (768,)              0.1812    -0.6978   0.0718    -0.0003   None      None     
 bert.encoder.layers.9.self_att.layernorm_before_attention.weight       (768,)              1.0439    0.3079    0.0356    0.9272    None      None     
 bert.encoder.layers.9.self_att.layernorm_before_attention.bias         (768,)              0.2362    -0.4849   0.0518    -0.0294   None      None     
 bert.encoder.layers.9.self_att.self_attention.project_q.weight         (768, 768)          0.2074    -0.1949   0.0417    0.0001    None      None     
 bert.encoder.layers.9.self_att.self_attention.project_q.bias           (768,)              0.3958    -0.3457   0.0851    -0.0041   None      None     
 bert.encoder.layers.9.self_att.self_attention.project_k.weight         (768, 768)          0.2590    -0.2180   0.0414    0.0000    None      None     
 bert.encoder.layers.9.self_att.self_attention.project_k.bias           (768,)              0.0175    -0.0164   0.0043    -0.0000   None      None     
 bert.encoder.layers.9.self_att.self_attention.project_v.weight         (768, 768)          0.1652    -0.1722   0.0323    -0.0000   None      None     
 bert.encoder.layers.9.self_att.self_attention.project_v.bias           (768,)              0.2128    -0.1453   0.0306    0.0004    None      None     
 bert.encoder.layers.9.self_att.self_attention.attention_out.weight     (768, 768)          0.5186    -0.3518   0.0298    -0.0000   None      None     
 bert.encoder.layers.9.self_att.self_attention.attention_out.bias       (768,)              0.3994    -0.1372   0.0472    0.0001    None      None     
 bert.encoder.layers.9.ffn.layernorm_before_ffn.weight                  (768,)              1.9355    0.8145    0.0584    0.9062    None      None     
 bert.encoder.layers.9.ffn.layernorm_before_ffn.bias                    (768,)              0.2278    -1.1396   0.0890    -0.0144   None      None     
 bert.encoder.layers.9.ffn.ffn.w_in.w.weight                            (3072, 768)         0.7158    -0.8184   0.0363    -0.0001   None      None     
 bert.encoder.layers.9.ffn.ffn.w_in.w.bias                              (3072,)             0.1675    -0.2059   0.0279    -0.0652   None      None     
 bert.encoder.layers.9.ffn.ffn.w_out.weight                             (768, 3072)         0.7974    -3.9609   0.0355    -0.0000   None      None     
 bert.encoder.layers.9.ffn.ffn.w_out.bias                               (768,)              0.2395    -0.5962   0.0718    0.0003    None      None     
 bert.encoder.layers.10.self_att.layernorm_before_attention.weight      (768,)              1.1250    0.3621    0.0425    0.9287    None      None     
 bert.encoder.layers.10.self_att.layernorm_before_attention.bias        (768,)              0.1010    -0.5327   0.0447    -0.0287   None      None     
 bert.encoder.layers.10.self_att.self_attention.project_q.weight        (768, 768)          0.2286    -0.2571   0.0432    0.0001    None      None     
 bert.encoder.layers.10.self_att.self_attention.project_q.bias          (768,)              0.5039    -0.5703   0.1152    -0.0053   None      None     
 bert.encoder.layers.10.self_att.self_attention.project_k.weight        (768, 768)          0.2008    -0.2247   0.0430    -0.0000   None      None     
 bert.encoder.layers.10.self_att.self_attention.project_k.bias          (768,)              0.0151    -0.0128   0.0040    0.0003    None      None     
 bert.encoder.layers.10.self_att.self_attention.project_v.weight        (768, 768)          0.2126    -0.1793   0.0322    -0.0000   None      None     
 bert.encoder.layers.10.self_att.self_attention.project_v.bias          (768,)              0.1393    -0.1130   0.0234    0.0006    None      None     
 bert.encoder.layers.10.self_att.self_attention.attention_out.weight    (768, 768)          0.3772    -0.3269   0.0292    0.0000    None      None     
 bert.encoder.layers.10.self_att.self_attention.attention_out.bias      (768,)              0.3435    -0.1484   0.0549    0.0000    None      None     
 bert.encoder.layers.10.ffn.layernorm_before_ffn.weight                 (768,)              2.6855    0.8208    0.1172    0.9019    None      None     
 bert.encoder.layers.10.ffn.layernorm_before_ffn.bias                   (768,)              0.5200    -1.6084   0.1023    -0.0149   None      None     
 bert.encoder.layers.10.ffn.ffn.w_in.w.weight                           (3072, 768)         0.4495    -0.3555   0.0369    -0.0002   None      None     
 bert.encoder.layers.10.ffn.ffn.w_in.w.bias                             (3072,)             0.2079    -0.2003   0.0266    -0.0623   None      None     
 bert.encoder.layers.10.ffn.ffn.w_out.weight                            (768, 3072)         1.3867    -3.3789   0.0366    0.0000    None      None     
 bert.encoder.layers.10.ffn.ffn.w_out.bias                              (768,)              0.1931    -0.5771   0.0759    -0.0001   None      None     
 bert.encoder.layers.11.self_att.layernorm_before_attention.weight      (768,)              1.4648    0.1282    0.0612    0.9287    None      None     
 bert.encoder.layers.11.self_att.layernorm_before_attention.bias        (768,)              0.7114    -0.8135   0.0572    -0.0281   None      None     
 bert.encoder.layers.11.self_att.self_attention.project_q.weight        (768, 768)          0.2323    -0.2732   0.0425    -0.0000   None      None     
 bert.encoder.layers.11.self_att.self_attention.project_q.bias          (768,)              0.5752    -0.5425   0.1353    -0.0032   None      None     
 bert.encoder.layers.11.self_att.self_attention.project_k.weight        (768, 768)          0.3684    -0.3782   0.0421    -0.0000   None      None     
 bert.encoder.layers.11.self_att.self_attention.project_k.bias          (768,)              0.0137    -0.0135   0.0038    -0.0000   None      None     
 bert.encoder.layers.11.self_att.self_attention.project_v.weight        (768, 768)          0.1975    -0.2230   0.0392    0.0000    None      None     
 bert.encoder.layers.11.self_att.self_attention.project_v.bias          (768,)              0.1022    -0.0562   0.0167    0.0011    None      None     
 bert.encoder.layers.11.self_att.self_attention.attention_out.weight    (768, 768)          0.2695    -0.4167   0.0360    -0.0000   None      None     
 bert.encoder.layers.11.self_att.self_attention.attention_out.bias      (768,)              0.1223    -0.1198   0.0479    0.0000    None      None     
 bert.encoder.layers.11.ffn.layernorm_before_ffn.weight                 (768,)              1.8320    0.8052    0.0639    0.9019    None      None     
 bert.encoder.layers.11.ffn.layernorm_before_ffn.bias                   (768,)              0.3113    -1.4912   0.0851    -0.0232   None      None     
 bert.encoder.layers.11.ffn.ffn.w_in.w.weight                           (3072, 768)         0.3254    -0.3140   0.0379    -0.0001   None      None     
 bert.encoder.layers.11.ffn.ffn.w_in.w.bias                             (3072,)             0.5869    -0.3696   0.0427    -0.0446   None      None     
 bert.encoder.layers.11.ffn.ffn.w_out.weight                            (768, 3072)         1.3506    -0.5981   0.0352    -0.0000   None      None     
 bert.encoder.layers.11.ffn.ffn.w_out.bias                              (768,)              0.2302    -0.5396   0.0599    -0.0006   None      None     
 bert.encoder.output_layernorm.weight                                   (768,)              0.8828    0.3752    0.0269    0.7495    None      None     
 bert.encoder.output_layernorm.bias                                     (768,)              0.2695    -0.1750   0.0498    -0.0145   None      None     
 bert.lm_head.dense.weight                                              (768, 768)          0.7461    -0.6357   0.0461    0.0005    None      None     
 bert.lm_head.dense.bias                                                (768,)              1.4668    -0.0598   0.0548    0.0255    None      None     
 bert.lm_head.layer_norm.weight                                         (768,)              3.3281    0.0815    0.4368    2.2773    None      None     
 bert.lm_head.layer_norm.bias                                           (768,)              1.1680    -1.4287   0.2644    0.1115    None      None     
 bert.lm_head.decoder.weight                                            (28996, 768)        0.6499    -0.9722   0.0448    -0.0138   None      None     
 bert.lm_head.decoder.bias                                              (28996,)            2.0469    -3.0273   0.1015    -0.0956   None      None     
 bert.pooler.dense.weight                                               (768, 768)          0.2336    -0.2296   0.0309    -0.0000   None      None     
 bert.pooler.dense.bias                                                 (768,)              0.0786    -0.0800   0.0341    -0.0008   None      None     
 dense.weight                                                           (2, 768)            3.1426    -3.5273   1.0264    -0.0064   None      None     
train | epoch   0 | Iter:      0/    22 | loss: 14.4213 | lr: 1.0000e-04, scale:   128.0000 | time: 1.413 avg_time: 1.413 | acc: 0.5536
train | epoch   0 | Iter:      1/    22 | loss: 12.7946 | lr: 1.0000e-04, scale:   128.0000 | time: 0.738 avg_time: 1.076 | acc: 0.6429
train | epoch   0 | Iter:      2/    22 | loss: 3.3481 | lr: 1.0000e-04, scale:   128.0000 | time: 0.723 avg_time: 0.958 | acc: 0.4464
train | epoch   0 | Iter:      3/    22 | loss: 6.5190 | lr: 1.0000e-04, scale:   128.0000 | time: 0.719 avg_time: 0.898 | acc: 0.5893
train | epoch   0 | Iter:      4/    22 | loss: 2.6054 | lr: 1.0000e-04, scale:   128.0000 | time: 0.706 avg_time: 0.860 | acc: 0.4821
train | epoch   0 | Iter:      5/    22 | loss: 5.7407 | lr: 1.0000e-04, scale:   128.0000 | time: 0.709 avg_time: 0.835 | acc: 0.3571
train | epoch   0 | Iter:      6/    22 | loss: 1.1850 | lr: 1.0000e-04, scale:   128.0000 | time: 0.708 avg_time: 0.817 | acc: 0.4107
train | epoch   0 | Iter:      7/    22 | loss: 1.8099 | lr: 1.0000e-04, scale:   128.0000 | time: 0.698 avg_time: 0.802 | acc: 0.6250
train | epoch   0 | Iter:      8/    22 | loss: 1.5534 | lr: 1.0000e-04, scale:   128.0000 | time: 0.758 avg_time: 0.797 | acc: 0.5357
train | epoch   0 | Iter:      9/    22 | loss: 1.0980 | lr: 1.0000e-04, scale:   128.0000 | time: 0.710 avg_time: 0.788 | acc: 0.5357
train | epoch   0 | Iter:     10/    22 | loss: 1.5680 | lr: 1.0000e-04, scale:   128.0000 | time: 0.714 avg_time: 0.781 | acc: 0.4643
train | epoch   0 | Iter:     11/    22 | loss: 1.0214 | lr: 1.0000e-04, scale:   128.0000 | time: 0.701 avg_time: 0.775 | acc: 0.5179
train | epoch   0 | Iter:     12/    22 | loss: 0.9701 | lr: 1.0000e-04, scale:   128.0000 | time: 0.709 avg_time: 0.770 | acc: 0.5714
train | epoch   0 | Iter:     13/    22 | loss: 0.9250 | lr: 1.0000e-04, scale:   128.0000 | time: 0.733 avg_time: 0.767 | acc: 0.6607
train | epoch   0 | Iter:     14/    22 | loss: 0.9223 | lr: 1.0000e-04, scale:   128.0000 | time: 0.714 avg_time: 0.764 | acc: 0.5536
train | epoch   0 | Iter:     15/    22 | loss: 1.0454 | lr: 1.0000e-04, scale:   128.0000 | time: 0.697 avg_time: 0.759 | acc: 0.6429
train | epoch   0 | Iter:     16/    22 | loss: 0.9062 | lr: 1.0000e-04, scale:   128.0000 | time: 0.738 avg_time: 0.758 | acc: 0.6964
train | epoch   0 | Iter:     17/    22 | loss: 1.1972 | lr: 1.0000e-04, scale:   128.0000 | time: 0.715 avg_time: 0.756 | acc: 0.5000
train | epoch   0 | Iter:     18/    22 | loss: 0.9250 | lr: 1.0000e-04, scale:   128.0000 | time: 0.717 avg_time: 0.754 | acc: 0.5357
train | epoch   0 | Iter:     19/    22 | loss: 1.1686 | lr: 1.0000e-04, scale:   128.0000 | time: 0.716 avg_time: 0.752 | acc: 0.6607
train | epoch   0 | Iter:     20/    22 | loss: 0.9163 | lr: 1.0000e-04, scale:   128.0000 | time: 0.749 avg_time: 0.752 | acc: 0.5179
train | epoch   0 | Iter:     21/    22 | loss: 0.9306 | lr: 1.0000e-04, scale:   128.0000 | time: 0.239 avg_time: 0.728 | acc: 0.5000
dev | epoch   0 | Iter:      0/     8 | loss: 2.5169
dev | epoch   0 | Iter:      1/     8 | loss: 1.8212
dev | epoch   0 | Iter:      2/     8 | loss: 2.0324
dev | epoch   0 | Iter:      3/     8 | loss: 2.8139
dev | epoch   0 | Iter:      4/     8 | loss: 1.9378
dev | epoch   0 | Iter:      5/     8 | loss: 1.8366
dev | epoch   0 | Iter:      6/     8 | loss: 2.4042
dev | epoch   0 | Iter:      7/     8 | loss: 1.9653
dev epoch 0:
accuracy: 38.24
train | epoch   1 | Iter:      0/    22 | loss: 1.5603 | lr: 1.0000e-04, scale:   128.0000 | time: 0.706 avg_time: 0.706 | acc: 0.4464
train | epoch   1 | Iter:      1/    22 | loss: 0.8625 | lr: 1.0000e-04, scale:   128.0000 | time: 0.756 avg_time: 0.731 | acc: 0.5179
train | epoch   1 | Iter:      2/    22 | loss: 1.4043 | lr: 1.0000e-04, scale:   128.0000 | time: 0.710 avg_time: 0.724 | acc: 0.5893
train | epoch   1 | Iter:      3/    22 | loss: 1.2174 | lr: 1.0000e-04, scale:   128.0000 | time: 0.713 avg_time: 0.721 | acc: 0.5893
train | epoch   1 | Iter:      4/    22 | loss: 0.8898 | lr: 1.0000e-04, scale:   128.0000 | time: 0.707 avg_time: 0.718 | acc: 0.5179
train | epoch   1 | Iter:      5/    22 | loss: 1.3553 | lr: 1.0000e-04, scale:   128.0000 | time: 0.830 avg_time: 0.737 | acc: 0.3929
train | epoch   1 | Iter:      6/    22 | loss: 0.8509 | lr: 1.0000e-04, scale:   128.0000 | time: 0.704 avg_time: 0.732 | acc: 0.4107
train | epoch   1 | Iter:      7/    22 | loss: 0.9890 | lr: 1.0000e-04, scale:   128.0000 | time: 0.711 avg_time: 0.730 | acc: 0.6429
train | epoch   1 | Iter:      8/    22 | loss: 1.2071 | lr: 1.0000e-04, scale:   128.0000 | time: 0.800 avg_time: 0.737 | acc: 0.4464
train | epoch   1 | Iter:      9/    22 | loss: 0.8647 | lr: 1.0000e-04, scale:   128.0000 | time: 0.697 avg_time: 0.733 | acc: 0.6429
train | epoch   1 | Iter:     10/    22 | loss: 0.8076 | lr: 1.0000e-04, scale:   128.0000 | time: 0.713 avg_time: 0.731 | acc: 0.4643
train | epoch   1 | Iter:     11/    22 | loss: 1.0950 | lr: 1.0000e-04, scale:   128.0000 | time: 0.833 avg_time: 0.740 | acc: 0.4286
train | epoch   1 | Iter:     12/    22 | loss: 0.8167 | lr: 1.0000e-04, scale:   128.0000 | time: 0.711 avg_time: 0.738 | acc: 0.4643
train | epoch   1 | Iter:     13/    22 | loss: 0.7933 | lr: 1.0000e-04, scale:   128.0000 | time: 0.794 avg_time: 0.742 | acc: 0.7500
train | epoch   1 | Iter:     14/    22 | loss: 0.9465 | lr: 1.0000e-04, scale:   128.0000 | time: 0.697 avg_time: 0.739 | acc: 0.5714
train | epoch   1 | Iter:     15/    22 | loss: 0.8255 | lr: 1.0000e-04, scale:   128.0000 | time: 0.714 avg_time: 0.737 | acc: 0.7143
train | epoch   1 | Iter:     16/    22 | loss: 0.7925 | lr: 1.0000e-04, scale:   128.0000 | time: 0.730 avg_time: 0.737 | acc: 0.5000
train | epoch   1 | Iter:     17/    22 | loss: 0.9398 | lr: 1.0000e-04, scale:   128.0000 | time: 0.798 avg_time: 0.740 | acc: 0.4107
train | epoch   1 | Iter:     18/    22 | loss: 0.8892 | lr: 1.0000e-04, scale:   128.0000 | time: 0.698 avg_time: 0.738 | acc: 0.4821
train | epoch   1 | Iter:     19/    22 | loss: 0.8104 | lr: 1.0000e-04, scale:   128.0000 | time: 0.717 avg_time: 0.737 | acc: 0.5893
train | epoch   1 | Iter:     20/    22 | loss: 0.9728 | lr: 1.0000e-04, scale:   128.0000 | time: 0.709 avg_time: 0.736 | acc: 0.6964
train | epoch   1 | Iter:     21/    22 | loss: 0.5882 | lr: 1.0000e-04, scale:   128.0000 | time: 0.147 avg_time: 0.709 | acc: 0.5000
dev | epoch   1 | Iter:      0/     8 | loss: 0.9625
dev | epoch   1 | Iter:      1/     8 | loss: 0.7893
dev | epoch   1 | Iter:      2/     8 | loss: 0.8528
dev | epoch   1 | Iter:      3/     8 | loss: 1.0442
dev | epoch   1 | Iter:      4/     8 | loss: 0.8252
dev | epoch   1 | Iter:      5/     8 | loss: 0.7920
dev | epoch   1 | Iter:      6/     8 | loss: 0.9179
dev | epoch   1 | Iter:      7/     8 | loss: 0.7970
dev epoch 1:
accuracy: 38.24
train | epoch   2 | Iter:      0/    22 | loss: 0.7845 | lr: 1.0000e-04, scale:   128.0000 | time: 0.710 avg_time: 0.710 | acc: 0.6429
train | epoch   2 | Iter:      1/    22 | loss: 0.9115 | lr: 1.0000e-04, scale:   128.0000 | time: 0.705 avg_time: 0.708 | acc: 0.5179
train | epoch   2 | Iter:      2/    22 | loss: 0.8792 | lr: 1.0000e-04, scale:   128.0000 | time: 0.728 avg_time: 0.715 | acc: 0.5000
train | epoch   2 | Iter:      3/    22 | loss: 0.8398 | lr: 1.0000e-04, scale:   128.0000 | time: 0.715 avg_time: 0.715 | acc: 0.5536
train | epoch   2 | Iter:      4/    22 | loss: 0.8949 | lr: 1.0000e-04, scale:   128.0000 | time: 0.709 avg_time: 0.714 | acc: 0.4821
train | epoch   2 | Iter:      5/    22 | loss: 0.7556 | lr: 1.0000e-04, scale:   128.0000 | time: 0.718 avg_time: 0.714 | acc: 0.6250
train | epoch   2 | Iter:      6/    22 | loss: 0.7358 | lr: 1.0000e-04, scale:   128.0000 | time: 0.769 avg_time: 0.722 | acc: 0.5893
train | epoch   2 | Iter:      7/    22 | loss: 0.8891 | lr: 1.0000e-04, scale:   128.0000 | time: 0.723 avg_time: 0.722 | acc: 0.4464
train | epoch   2 | Iter:      8/    22 | loss: 0.7380 | lr: 1.0000e-04, scale:   128.0000 | time: 0.715 avg_time: 0.721 | acc: 0.4821
train | epoch   2 | Iter:      9/    22 | loss: 0.7599 | lr: 1.0000e-04, scale:   128.0000 | time: 0.715 avg_time: 0.721 | acc: 0.5893
train | epoch   2 | Iter:     10/    22 | loss: 0.8546 | lr: 1.0000e-04, scale:   128.0000 | time: 0.726 avg_time: 0.721 | acc: 0.5536
train | epoch   2 | Iter:     11/    22 | loss: 0.8558 | lr: 1.0000e-04, scale:   128.0000 | time: 0.716 avg_time: 0.721 | acc: 0.6071
train | epoch   2 | Iter:     12/    22 | loss: 0.7748 | lr: 1.0000e-04, scale:   128.0000 | time: 0.700 avg_time: 0.719 | acc: 0.5714
train | epoch   2 | Iter:     13/    22 | loss: 0.7635 | lr: 1.0000e-04, scale:   128.0000 | time: 0.731 avg_time: 0.720 | acc: 0.4643
train | epoch   2 | Iter:     14/    22 | loss: 0.6982 | lr: 1.0000e-04, scale:   128.0000 | time: 0.719 avg_time: 0.720 | acc: 0.6071
train | epoch   2 | Iter:     15/    22 | loss: 0.7415 | lr: 1.0000e-04, scale:   128.0000 | time: 0.752 avg_time: 0.722 | acc: 0.6607
train | epoch   2 | Iter:     16/    22 | loss: 0.7957 | lr: 1.0000e-04, scale:   128.0000 | time: 0.717 avg_time: 0.722 | acc: 0.6429
train | epoch   2 | Iter:     17/    22 | loss: 0.7398 | lr: 1.0000e-04, scale:   128.0000 | time: 0.701 avg_time: 0.721 | acc: 0.5714
train | epoch   2 | Iter:     18/    22 | loss: 0.7188 | lr: 1.0000e-04, scale:   128.0000 | time: 0.718 avg_time: 0.720 | acc: 0.5536
train | epoch   2 | Iter:     19/    22 | loss: 0.7369 | lr: 1.0000e-04, scale:   128.0000 | time: 0.718 avg_time: 0.720 | acc: 0.5714
train | epoch   2 | Iter:     20/    22 | loss: 0.7439 | lr: 1.0000e-04, scale:   128.0000 | time: 0.713 avg_time: 0.720 | acc: 0.5536
train | epoch   2 | Iter:     21/    22 | loss: 0.4863 | lr: 1.0000e-04, scale:   128.0000 | time: 0.152 avg_time: 0.694 | acc: 0.5000
dev | epoch   2 | Iter:      0/     8 | loss: 0.5470
dev | epoch   2 | Iter:      1/     8 | loss: 0.7213
dev | epoch   2 | Iter:      2/     8 | loss: 0.6518
dev | epoch   2 | Iter:      3/     8 | loss: 0.5680
dev | epoch   2 | Iter:      4/     8 | loss: 0.6840
dev | epoch   2 | Iter:      5/     8 | loss: 0.7136
dev | epoch   2 | Iter:      6/     8 | loss: 0.6081
dev | epoch   2 | Iter:      7/     8 | loss: 0.6283
dev epoch 2:
accuracy: 64.22
train | epoch   3 | Iter:      0/    22 | loss: 0.8199 | lr: 1.0000e-04, scale:   128.0000 | time: 0.705 avg_time: 0.705 | acc: 0.5893
train | epoch   3 | Iter:      1/    22 | loss: 0.7530 | lr: 1.0000e-04, scale:   128.0000 | time: 0.722 avg_time: 0.713 | acc: 0.6429
train | epoch   3 | Iter:      2/    22 | loss: 0.7371 | lr: 1.0000e-04, scale:   128.0000 | time: 0.900 avg_time: 0.776 | acc: 0.5000
train | epoch   3 | Iter:      3/    22 | loss: 0.8154 | lr: 1.0000e-04, scale:   128.0000 | time: 0.722 avg_time: 0.762 | acc: 0.5179
train | epoch   3 | Iter:      4/    22 | loss: 0.6819 | lr: 1.0000e-04, scale:   128.0000 | time: 0.719 avg_time: 0.754 | acc: 0.5714
train | epoch   3 | Iter:      5/    22 | loss: 0.7031 | lr: 1.0000e-04, scale:   128.0000 | time: 0.751 avg_time: 0.753 | acc: 0.6786
train | epoch   3 | Iter:      6/    22 | loss: 0.7511 | lr: 1.0000e-04, scale:   128.0000 | time: 0.701 avg_time: 0.746 | acc: 0.6250
train | epoch   3 | Iter:      7/    22 | loss: 0.6997 | lr: 1.0000e-04, scale:   128.0000 | time: 0.729 avg_time: 0.743 | acc: 0.6071
train | epoch   3 | Iter:      8/    22 | loss: 0.7349 | lr: 1.0000e-04, scale:   128.0000 | time: 0.816 avg_time: 0.752 | acc: 0.5536
train | epoch   3 | Iter:      9/    22 | loss: 0.7117 | lr: 1.0000e-04, scale:   128.0000 | time: 0.714 avg_time: 0.748 | acc: 0.4821
train | epoch   3 | Iter:     10/    22 | loss: 0.7698 | lr: 1.0000e-04, scale:   128.0000 | time: 0.706 avg_time: 0.744 | acc: 0.5357
train | epoch   3 | Iter:     11/    22 | loss: 0.7089 | lr: 1.0000e-04, scale:   128.0000 | time: 0.718 avg_time: 0.742 | acc: 0.6607
train | epoch   3 | Iter:     12/    22 | loss: 0.6946 | lr: 1.0000e-04, scale:   128.0000 | time: 0.713 avg_time: 0.740 | acc: 0.5893
train | epoch   3 | Iter:     13/    22 | loss: 0.7605 | lr: 1.0000e-04, scale:   128.0000 | time: 0.704 avg_time: 0.737 | acc: 0.5536
train | epoch   3 | Iter:     14/    22 | loss: 0.7069 | lr: 1.0000e-04, scale:   128.0000 | time: 0.725 avg_time: 0.736 | acc: 0.6429
train | epoch   3 | Iter:     15/    22 | loss: 0.7586 | lr: 1.0000e-04, scale:   128.0000 | time: 0.711 avg_time: 0.735 | acc: 0.6964
train | epoch   3 | Iter:     16/    22 | loss: 0.7057 | lr: 1.0000e-04, scale:   128.0000 | time: 0.712 avg_time: 0.733 | acc: 0.6786
train | epoch   3 | Iter:     17/    22 | loss: 0.6385 | lr: 1.0000e-04, scale:   128.0000 | time: 0.714 avg_time: 0.732 | acc: 0.5893
train | epoch   3 | Iter:     18/    22 | loss: 0.7539 | lr: 1.0000e-04, scale:   128.0000 | time: 0.713 avg_time: 0.731 | acc: 0.4286
train | epoch   3 | Iter:     19/    22 | loss: 0.7028 | lr: 1.0000e-04, scale:   128.0000 | time: 0.710 avg_time: 0.730 | acc: 0.6786
train | epoch   3 | Iter:     20/    22 | loss: 0.7907 | lr: 1.0000e-04, scale:   128.0000 | time: 0.713 avg_time: 0.729 | acc: 0.6786
train | epoch   3 | Iter:     21/    22 | loss: 0.2575 | lr: 1.0000e-04, scale:   128.0000 | time: 0.145 avg_time: 0.703 | acc: 1.0000
dev | epoch   3 | Iter:      0/     8 | loss: 0.6827
dev | epoch   3 | Iter:      1/     8 | loss: 0.6538
dev | epoch   3 | Iter:      2/     8 | loss: 0.6837
dev | epoch   3 | Iter:      3/     8 | loss: 0.8178
dev | epoch   3 | Iter:      4/     8 | loss: 0.7252
dev | epoch   3 | Iter:      5/     8 | loss: 0.6322
dev | epoch   3 | Iter:      6/     8 | loss: 0.7801
dev | epoch   3 | Iter:      7/     8 | loss: 0.5875
dev epoch 3:
accuracy: 56.13
train | epoch   4 | Iter:      0/    22 | loss: 0.6559 | lr: 1.0000e-04, scale:   128.0000 | time: 0.705 avg_time: 0.705 | acc: 0.6786
train | epoch   4 | Iter:      1/    22 | loss: 0.7001 | lr: 1.0000e-04, scale:   128.0000 | time: 0.734 avg_time: 0.719 | acc: 0.6786
train | epoch   4 | Iter:      2/    22 | loss: 0.6679 | lr: 1.0000e-04, scale:   128.0000 | time: 0.747 avg_time: 0.729 | acc: 0.7500
train | epoch   4 | Iter:      3/    22 | loss: 0.6841 | lr: 1.0000e-04, scale:   128.0000 | time: 0.705 avg_time: 0.723 | acc: 0.6250
train | epoch   4 | Iter:      4/    22 | loss: 0.6512 | lr: 1.0000e-04, scale:   128.0000 | time: 0.719 avg_time: 0.722 | acc: 0.5357
train | epoch   4 | Iter:      5/    22 | loss: 0.6236 | lr: 1.0000e-04, scale:   128.0000 | time: 0.806 avg_time: 0.736 | acc: 0.5714
train | epoch   4 | Iter:      6/    22 | loss: 0.6359 | lr: 1.0000e-04, scale:   128.0000 | time: 0.885 avg_time: 0.757 | acc: 0.6250
train | epoch   4 | Iter:      7/    22 | loss: 0.6365 | lr: 1.0000e-04, scale:   128.0000 | time: 0.711 avg_time: 0.751 | acc: 0.7143
train | epoch   4 | Iter:      8/    22 | loss: 0.6479 | lr: 1.0000e-04, scale:   128.0000 | time: 0.726 avg_time: 0.749 | acc: 0.6071
train | epoch   4 | Iter:      9/    22 | loss: 0.6251 | lr: 1.0000e-04, scale:   128.0000 | time: 0.723 avg_time: 0.746 | acc: 0.6607
train | epoch   4 | Iter:     10/    22 | loss: 0.6337 | lr: 1.0000e-04, scale:   128.0000 | time: 0.706 avg_time: 0.742 | acc: 0.6429
train | epoch   4 | Iter:     11/    22 | loss: 0.6486 | lr: 1.0000e-04, scale:   256.0000 | time: 0.723 avg_time: 0.741 | acc: 0.6607
train | epoch   4 | Iter:     12/    22 | loss: 0.6758 | lr: 1.0000e-04, scale:   256.0000 | time: 0.710 avg_time: 0.738 | acc: 0.6250
train | epoch   4 | Iter:     13/    22 | loss: 0.5998 | lr: 1.0000e-04, scale:   256.0000 | time: 0.710 avg_time: 0.736 | acc: 0.7857
train | epoch   4 | Iter:     14/    22 | loss: 0.6304 | lr: 1.0000e-04, scale:   256.0000 | time: 0.722 avg_time: 0.735 | acc: 0.7500
slurmstepd: error: *** JOB 159877 ON g0019 CANCELLED AT 2022-03-20T23:42:54 ***
